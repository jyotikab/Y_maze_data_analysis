{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "import sklearn as skl\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler,LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import LeaveOneOut, LeaveOneGroupOut, GroupKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import scipy as sp\n",
    "import matplotlib.gridspec as gridspec\n",
    "# import more_itertools as mit\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import scipy.io as sio\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from collections import Counter\n",
    "import funcs as func\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pdb\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jyotika/Utils/hddm/')\n",
    "\n",
    "import hddm\n",
    "\n",
    "data_dir = \"./Data/processed_data/Y_maze/data_with_animal_ids/\"\n",
    "data_target_dir = \"./Data/processed_data/Y_maze/data_with_animal_ids/for_b_cpp_calculation/\"\n",
    "data_target_dir2 = \"./Data/processed_data/Y_maze/data_with_animal_ids/for_ddm_models/\"\n",
    "figure_dir = \"./Figures/Y_maze/\"\n",
    "\n",
    "plt.rcParams[\"figure.facecolor\"] = \"w\"\n",
    "import sys\n",
    "\n",
    "\n",
    "#from my_sklearn_tools.pca_regressors import LogisticPCR\n",
    "\n",
    "sys.path.append(\"/home/bahuguna/Work/CBGT_CMU/analysis/\")\n",
    "from simulation_functions_loki import Simulation\n",
    "\n",
    "postfix = \"_with_binom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_conflicts = pd.read_csv(data_dir+\"all_experiments_df_with_DTs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grp in all_conflicts.groupby([\"conflict\",\"volatility\",\"session\"]):\n",
    "    print(grp[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_changes = np.where(grp[1][\"block\"]!=grp[1][\"block\"].shift())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp[1].iloc[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_t0 = np.where(np.logical_and(grp[1][\"block\"]==\"left\",grp[1][\"rewarded_code\"]==1))[0]\n",
    "bl_t0 = np.where(grp[1][\"block\"]==\"left\")[0]\n",
    "ind_t1 = np.where(np.logical_and(grp[1][\"block\"]==\"right\",grp[1][\"rewarded_code\"]==1))[0]\n",
    "bl_t1 = np.where(grp[1][\"block\"]==\"right\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrewarded_t0 =  np.sort(list(set(bl_t0)-set(ind_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrewarded_t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because Julia does not save her reward frames only the actions which were actually rewarded (which will be equivalent to the reward data frame only if performance == reward probability in the block)\n",
    "\n",
    "def generate_reward_frame(rew,conf,n_trials):\n",
    "    if conf == \"No\":\n",
    "        ba,nba = 0.9,0.0\n",
    "    elif conf == \"Low\":\n",
    "        ba,nba = 0.9,0.1\n",
    "    elif conf == \"High\":\n",
    "        ba,nba = 0.75,0.25\n",
    "    block_changes = np.where(rew[\"block\"]!=rew[\"block\"].shift())[0]\n",
    "    ind_t0 = []\n",
    "    ind_t1 = []\n",
    "    for i,bc_ind in enumerate(block_changes):\n",
    "        print(ba,nba)\n",
    "        start = bc_ind\n",
    "        if i < len(block_changes)-1:\n",
    "            end = block_changes[i+1]\n",
    "        else:\n",
    "            end = -1\n",
    "            \n",
    "        dat_slice = rew.iloc[start:end].copy()\n",
    "        block = np.unique(dat_slice[\"block\"])\n",
    "        if len(block)==0:\n",
    "            continue\n",
    "        #print(\"block\",block)\n",
    "        if len(block)>1:\n",
    "            print(\"problem !!\")\n",
    "        else:\n",
    "            block = block[0]\n",
    "        print(block)\n",
    "\n",
    "        if block == \"left\":\n",
    "            # Check which trials are rewarded\n",
    "            ind_rewarded_opt = start+np.where(np.logical_and(dat_slice[\"rewarded_code\"]==1,dat_slice[\"chosen_action\"]==\"left\"))[0]\n",
    "            ind_rewarded_subopt = start+np.where(np.logical_and(dat_slice[\"rewarded_code\"]==1,dat_slice[\"chosen_action\"]==\"right\"))[0]\n",
    "            all_opt = start+np.where(dat_slice[\"chosen_action\"]==\"left\")[0]\n",
    "            all_subopt = start+np.where(dat_slice[\"chosen_action\"]==\"right\")[0]\n",
    "        elif block == \"right\":\n",
    "            ind_rewarded_subopt = start+np.where(np.logical_and(dat_slice[\"rewarded_code\"]==1,dat_slice[\"chosen_action\"]==\"left\"))[0]\n",
    "            ind_rewarded_opt = start+np.where(np.logical_and(dat_slice[\"rewarded_code\"]==1,dat_slice[\"chosen_action\"]==\"right\"))[0]\n",
    "            all_opt = start+np.where(dat_slice[\"chosen_action\"]==\"right\")[0]\n",
    "            all_subopt = start+np.where(dat_slice[\"chosen_action\"]==\"left\")[0]\n",
    "\n",
    "        print(\"rewarded_opt\",ind_rewarded_opt,len(ind_rewarded_opt))\n",
    "        print(\"rewarded_subopt\",ind_rewarded_subopt,len(ind_rewarded_subopt))\n",
    "\n",
    "\n",
    "        num_b,num_un = int(len(dat_slice)*ba),int(len(dat_slice)*nba)\n",
    "        print(\"should_be_rewarded_opt\",num_b)\n",
    "        print(\"should_be_rewarded_subopt\",num_un)\n",
    "#         if block == \"left\":\n",
    "#             print(\"left,right =\",num_b,num_un )\n",
    "#         elif block == \"right\":\n",
    "#             print(\"right,left =\",num_b,num_un )\n",
    "\n",
    "#         ind_unrewarded_opt = list(set(np.arange(start,end,1))-set(ind_rewarded_opt)) #- set(ind_rewarded_t1))\n",
    "#         ind_unrewarded_subopt = list(set(np.arange(start,end,1))-set(ind_rewarded_subopt)) #- set(ind_rewarded_t0))    \n",
    "        ind_unrewarded_opt = list(set(all_opt)-set(ind_rewarded_opt)) #- set(ind_rewarded_t1))\n",
    "        ind_unrewarded_subopt = list(set(all_subopt)-set(ind_rewarded_subopt)) #- set(ind_rewarded_t0))    \n",
    "        rem_pool = list(set(np.arange(start,end,1)) - set(ind_rewarded_opt) - set(ind_unrewarded_opt) - set(ind_rewarded_subopt) - set(ind_unrewarded_subopt))\n",
    "        pool_for_opt = ind_unrewarded_subopt #list(set(np.arange(start,end,1))- set(ind_rewarded_opt) - set(ind_rewarded_subopt))\n",
    "        pool_for_subopt = ind_unrewarded_opt\n",
    "        \n",
    "        print(\"rem_pool\",rem_pool)\n",
    "        \n",
    "        print(\"unrewarded_opt\",ind_unrewarded_opt)\n",
    "        print(\"unrewarded_subopt\",ind_unrewarded_subopt)\n",
    "        print(\"pool\",pool_for_opt)\n",
    "        num_to_be_rewarded_b = num_b - len(ind_rewarded_opt)\n",
    "        num_to_be_rewarded_nb = num_un - len(ind_rewarded_subopt)\n",
    "\n",
    "        print(num_to_be_rewarded_b,num_to_be_rewarded_nb)\n",
    "        \n",
    "        rem_b = 0\n",
    "        if num_to_be_rewarded_b > 0:\n",
    "            if num_to_be_rewarded_b> len(pool_for_opt):\n",
    "                rem_b = num_to_be_rewarded_b - len(pool_for_opt)\n",
    "                num_to_be_rewarded_b = len(pool_for_opt)\n",
    "#                 if rem_b > len(rem_pool):\n",
    "#                     rem_b = len(rem_pool)\n",
    "            else:\n",
    "                rem_b = 0\n",
    "                \n",
    "            to_be_rewarded_b = list(np.random.choice(pool_for_opt,num_to_be_rewarded_b,replace=False)) #+ list(np.random.choice(rem_pool,rem_b,replace=False))\n",
    "                                                         \n",
    "        else:\n",
    "            to_be_rewarded_b = []\n",
    "         \n",
    "        rem_nb = 0\n",
    "        if num_to_be_rewarded_nb > 0:\n",
    "#             rem_nb = ind_unrewarded_opt   #list(set(ind_unrewarded_subopt) -set(to_be_rewarded_b))\n",
    "            if num_to_be_rewarded_nb >len(pool_for_subopt):\n",
    "                rem_nb = num_to_be_rewarded_nb - len(pool_for_subopt)                                                                                              \n",
    "                num_to_be_rewarded_nb =  len(pool_for_subopt)#num_to_be_rewarded_nb\n",
    "#                 if rem_nb > len(rem_pool):\n",
    "#                     rem_nb = len(rem_pool)\n",
    "#             else:\n",
    "            else:\n",
    "                rem_nb = 0\n",
    "#                 num_to_be_rewarded_nb = len(rem_nb)\n",
    "            to_be_rewarded_nb = list(np.random.choice(pool_for_subopt,num_to_be_rewarded_nb,replace=False)) #+ list(np.random.choice(rem_pool,rem_nb,replace=False))\n",
    "                \n",
    "        else:\n",
    "            to_be_rewarded_nb = []\n",
    "        \n",
    "        # where to put rem_pool\n",
    "        if rem_b > rem_nb:\n",
    "            to_be_rewarded_b = np.hstack((to_be_rewarded_b,rem_pool))\n",
    "        else:\n",
    "            to_be_rewarded_nb = np.hstack((to_be_rewarded_nb,rem_pool))\n",
    "        # add whatever remains to opt\n",
    "#         rem = list(set(rem_nb)-set(to_be_rewarded_nb))\n",
    "            \n",
    "        final_ind_rewarded_opt = np.sort(np.hstack((ind_rewarded_opt,to_be_rewarded_b)))\n",
    "        final_ind_rewarded_subopt = np.sort(np.hstack((ind_rewarded_subopt,to_be_rewarded_nb)))\n",
    "        print(\"opt_before\",ind_rewarded_opt)\n",
    "        print(\"subopt_before\",ind_rewarded_subopt)\n",
    "\n",
    "        print(\"opt_after\",final_ind_rewarded_opt)\n",
    "        print(\"subopt_after\",final_ind_rewarded_subopt)\n",
    "        reward_prob = (len(final_ind_rewarded_opt)+len(final_ind_rewarded_subopt))/len(dat_slice)\n",
    "        print(\"checkin rew prob\",ba,nba,reward_prob)\n",
    "        if ((ba+nba)-reward_prob) > 0.1:\n",
    "            print(\"Problems !!!\")\n",
    "            print(dat_slice)\n",
    "            #pdb.set_trace()\n",
    "        \n",
    "        print(\"intersection\",set(final_ind_rewarded_opt).intersection(final_ind_rewarded_subopt))\n",
    "        if len(set(final_ind_rewarded_opt).intersection(final_ind_rewarded_subopt)) != 0:\n",
    "            print(\"same action rewarded twice\")\n",
    "            pdb.set_trace()\n",
    "        \n",
    "        if block == \"left\":\n",
    "            ind_t0.append(final_ind_rewarded_opt)\n",
    "            ind_t1.append(final_ind_rewarded_subopt)\n",
    "        elif block == \"right\":\n",
    "            ind_t0.append(final_ind_rewarded_subopt)\n",
    "            ind_t1.append(final_ind_rewarded_opt)\n",
    "            \n",
    "        #print(rew.iloc[final_ind_rewarded_subopt][[\"chosen_action\",\"block\",\"rewarded\"]])\n",
    "#     print(ind_t0,ind_t1)\n",
    "    \n",
    "    return np.hstack(ind_t0).astype(int), np.hstack(ind_t1).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def conv_rew_df_t_epochs_fmt(rew,cond,conf,vol,session):\n",
    "    # Trial is constant, and first action is always left\n",
    "    # For the general case, save the t_epochs df during the simulation\n",
    "    # t0 == left\n",
    "    #r_df = rew.loc[rew[\"data_type\"]==\"reward_df\"]\n",
    "    n_trials = len(rew)\n",
    "    reward = np.random.normal(loc=1.0,scale=0.01,size=n_trials)\n",
    "    #print(reward)\n",
    "    t_epochs = pd.DataFrame(columns=[\"r_t0\",\"r_t1\",\"cp\",\"epoch_number\",\"reward_p_t0\",\"session\",\"conflict\",\"volatility\",\"condition\",\"p_id_solution\",\"action_history\",\"chosen_action\",\"trial_num\",\"animal_id\"])\n",
    "    n_trials =  len(rew) #int(np.unique(rew[\"n_trials\"])[0])\n",
    "    cp = np.zeros(n_trials)\n",
    "    #print(n_trials)\n",
    "    cp_idx = np.where(rew[\"block\"]!=rew[\"block\"].shift())\n",
    "    cp[cp_idx] = 1\n",
    "    \n",
    "    r_t0 = np.zeros(n_trials) # always left\n",
    "    r_t1 =np.zeros(n_trials)\n",
    "    \n",
    "    ind_t0,ind_t1 = generate_reward_frame(rew,conf,n_trials)\n",
    "#     print(\"ind_t0\",ind_t0)\n",
    "#     print(\"ind_t1\",ind_t1)\n",
    "    r_t0[ind_t0] = reward[ind_t0]\n",
    "    r_t1[ind_t1] = reward[ind_t1]\n",
    "    t_epochs[\"r_t0\"] = r_t0\n",
    "    t_epochs[\"r_t1\"] = r_t1\n",
    "    \n",
    "    all_inds = np.arange(0,n_trials)\n",
    "#     print(\"all_inds\",all_inds)\n",
    "    #print(\"t_epochs\",t_epochs)\n",
    "    t_epochs[\"cp\"] = cp\n",
    "    t_epochs[\"epoch_number\"] = rew.iloc[all_inds][\"block_num\"].values\n",
    "    block = list(rew.iloc[all_inds][\"block\"])\n",
    "    chosen_action = list(rew.iloc[all_inds][\"chosen_action\"])\n",
    "    \n",
    "    rew_p_t0 = np.zeros(n_trials)\n",
    "    rew_p_t0[ind_t0] = 1.0\n",
    "    t_epochs[\"reward_p_t0\"] = rew_p_t0\n",
    "    t_epochs[\"chosen_action\"] = chosen_action\n",
    "    t_epochs[\"rewarded\"] = rew[\"rewarded\"].values\n",
    "    t_epochs[\"action_history\"] = [ 0 if x == \"left\" else 1 for x in chosen_action]\n",
    "    t_epochs[\"p_id_solution\"] = list(block)\n",
    "    t_epochs[\"optimal\"] = list(block)\n",
    "    t_epochs[\"conflict\"] = conf\n",
    "    t_epochs[\"condition\"] = cond\n",
    "    t_epochs[\"volatility\"] = vol\n",
    "    t_epochs[\"session\"] = session\n",
    "    t_epochs[\"RT(ms)\"] = rew.iloc[all_inds][\"RT(ms)\"].values\n",
    "    t_epochs[\"animal_id\"] = rew.iloc[all_inds][\"animal_id\"].values\n",
    "    t_epochs[\"trial_num\"] = list(rew.iloc[all_inds][\"trial_num\"])\n",
    "    t_epochs[\"block_num\"] = list(rew.iloc[all_inds][\"block_num\"])\n",
    "    \n",
    "    #print(\"final\")\n",
    "    print(\"====================================\")\n",
    "    print(t_epochs.loc[(t_epochs[\"chosen_action\"]!=t_epochs[\"optimal\"])&(t_epochs[\"rewarded\"]==\"rewarded\")][[\"optimal\",\"chosen_action\",\"r_t0\",\"r_t1\",\"rewarded\"]])\n",
    "    \n",
    "    \n",
    "    return t_epochs\n",
    "    #print(t_epochs)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the batches into individual trials and save them as seperate .csv\n",
    "for grp in all_conflicts.groupby([\"conflict\",\"volatility\",\"condition\",\"session\"]): # Usually session is a proxy for animal id\n",
    "#     if seed == '2807188':\n",
    "#         continue\n",
    "    rew = grp[1].copy()\n",
    "    if len(np.unique(rew[\"animal_id\"]))>1:\n",
    "        print(\"more than one animal in this session !!\")\n",
    "    #print(grp[0])\n",
    "    #print(rew.loc[(rew[\"chosen_action\"]!=rew[\"block\"])&(rew[\"rewarded\"]==\"rewarded\")][[\"block\",\"chosen_action\",\"rewarded\"]])\n",
    "    cond = grp[0][2]\n",
    "    conf = grp[0][0]\n",
    "    vol = grp[0][1]\n",
    "    sess = grp[0][3]\n",
    "    print(\"actual_data\")\n",
    "    print(\"==========================================\")\n",
    "    print(rew.loc[(rew[\"chosen_action\"]!=rew[\"block\"])&(rew[\"rewarded\"]==\"rewarded\")][[\"block\",\"chosen_action\",\"rewarded\"]])\n",
    "    print(len(rew.loc[(rew[\"chosen_action\"]!=rew[\"block\"])&(rew[\"rewarded\"]==\"rewarded\")][[\"block\",\"chosen_action\",\"rewarded\"]]))\n",
    "    \n",
    "    \n",
    "    b_cpp_compatible_format = conv_rew_df_t_epochs_fmt(rew,cond,conf,vol,sess)\n",
    "    b_cpp_compatible_format = b_cpp_compatible_format.rename(columns={'RT(ms)':'rt'})\n",
    "    b_cpp_compatible_format[\"rewarded\"] = [1 if x ==\"rewarded\" else 0  for x in rew[\"rewarded\"]]\n",
    "    print(\"animal_id\",np.unique(b_cpp_compatible_format[\"animal_id\"]))\n",
    "    print(\"================================\")\n",
    "    print(b_cpp_compatible_format.loc[(b_cpp_compatible_format[\"chosen_action\"]!=b_cpp_compatible_format[\"optimal\"])&(b_cpp_compatible_format[\"rewarded\"]==1)][[\"optimal\",\"chosen_action\",\"r_t0\",\"r_t1\",\"rewarded\"]])\n",
    "    print(len(b_cpp_compatible_format.loc[(b_cpp_compatible_format[\"chosen_action\"]!=b_cpp_compatible_format[\"optimal\"])&(b_cpp_compatible_format[\"rewarded\"]==1)][[\"optimal\",\"chosen_action\",\"r_t0\",\"r_t1\",\"rewarded\"]]))\n",
    "    print(cond,conf,vol,sess)\n",
    "    filename = cond+\"_\"+conf+\"_\"+vol+\"_\"+str(sess)+\".csv\"\n",
    "    b_cpp_compatible_format.to_csv(data_target_dir+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rew.loc[(rew[\"chosen_action\"]!=rew[\"block\"])&(rew[\"rewarded\"]==\"rewarded\")][[\"block\",\"chosen_action\",\"rewarded\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_cpp_compatible_format.loc[(b_cpp_compatible_format[\"chosen_action\"]!=b_cpp_compatible_format[\"optimal\"])&(b_cpp_compatible_format[\"rewarded\"]==1)][[\"r_t0\",\"r_t1\",\"optimal\",\"chosen_action\",\"rewarded\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_cpp_compatible_format[[\"chosen_action\",\"optimal\",\"rewarded\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rew[[\"chosen_action\",\"block\",\"rewarded\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_cpp_compatible_format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subj_data_files = glob.glob(data_target_dir+'*[!block]_[0-9]*[!with_b_cpp].csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_data_files = glob.glob(data_target_dir+'*[!block]_*[0-9]*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in subj_data_files:\n",
    "    if \"iSPN-Control_High_Low_0\" in x:\n",
    "        print(\"found!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filen = subj_data_files[0]\n",
    "filen.split('/')[-1].split('_')[3].split('.csv')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir(\"/home/bahuguna/Work/CBGT_CMU/analysis/\")\n",
    "\n",
    "#data_target_dir1 = \"../cbgt2_plasticity/Data/var_lambda/10/for_b_cpp_calculation/\"\n",
    "# data_target_dir1 = \"../cbgt2_plasticity/Data/competition/for_b_cpp_calculation/\"\n",
    "print(os.getcwd())\n",
    "# cmd = \"python binary_ddm_rl_simulation_p.py ymaze \"\n",
    "cmd = \"python binary_ddm_rl_simulation_p.py ymaze_binom \"\n",
    "cmd = cmd + data_target_dir\n",
    "output = os.system(cmd)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b_cpp_path = '/home/bahuguna/Work/CBGT_CMU/cbgt2_plasticity/Data/competition/for_b_cpp_calculation/simulated_data/'\n",
    "# b_cpp_path = data_target_dir+'/simulated_data/'\n",
    "b_cpp_path = data_target_dir+'/simulated_data_binom/'\n",
    "\n",
    "files = glob.glob(b_cpp_path+\"*[0-9]*.pkl\")\n",
    "import pickle\n",
    "\n",
    "print(files)\n",
    "\n",
    "final_b_cpp_df = pd.DataFrame()\n",
    "\n",
    "for f in files:\n",
    "    print(f)\n",
    "    if \"with\" in f.split('/')[-1]:\n",
    "        continue\n",
    "    print(f)\n",
    "    cond = f.split('/')[-1].split('_condition_')[1].split('_')[0]\n",
    "    conf = f.split('/')[-1].split('_conflict_')[1].split('_')[0]\n",
    "    session = f.split('_session_')[1].split('.pkl')[0]\n",
    "    volatility = f.split('_volatility_')[1].split('_')[0]\n",
    "    \n",
    "    \n",
    "    filesrc = cond+\"_\"+conf+\"_\"+volatility+\"_\"+session+\".csv\"\n",
    "    filedest = cond+\"_\"+conf+\"_\"+volatility+\"_\"+session+\"with_b_cpp.csv\"\n",
    "    \n",
    "    temp = pd.read_csv(data_target_dir+filesrc)\n",
    "    #print(temp[\"rt\"])\n",
    "    sim = pickle.load(open(f,\"rb\"))\n",
    "    ideal_B = sim.ideal_B\n",
    "    cpp = sim.CPP\n",
    "    b_t0 = sim.B[:,0]\n",
    "    b_t1 = sim.B[:,1]\n",
    "    MC = sim.MC\n",
    "    lr = sim.lr\n",
    "    hr = sim.H\n",
    "    sF = sim.sF\n",
    "    u_val = sim.u_val_all\n",
    "    n_val = sim.n_val_all\n",
    "    \n",
    "    \n",
    "    temp[\"cpp\"] = cpp\n",
    "    temp[\"ideal_B\"] = ideal_B\n",
    "    temp[\"b_t0\"] = b_t0 \n",
    "    temp[\"b_t1\"] = b_t1\n",
    "    temp[\"MC\"] = MC\n",
    "    temp[\"learning_rate\"] = lr\n",
    "    temp[\"H(hazard_rate)\"] = hr\n",
    "    temp[\"sigma_estimated\"] = sF\n",
    "    temp[\"rpe_t0\"] = sim.rpe[:,0]\n",
    "    temp[\"rpe_t1\"] = sim.rpe[:,1]    \n",
    "    temp[\"u_val\"] = u_val\n",
    "    temp[\"n_val\"] = n_val\n",
    "    print(\"animal_id\",np.unique(temp[\"animal_id\"]))\n",
    "    temp.to_csv(data_target_dir+filedest)\n",
    "    final_b_cpp_df = final_b_cpp_df.append(temp)\n",
    "    \n",
    "    \n",
    "    #print(temp)\n",
    "    \n",
    "final_b_cpp_df.to_csv(data_target_dir+\"for_av_fits_hddm_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.rpe[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_b_cpp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_b_cpp_df = pd.read_csv(data_target_dir+\"for_av_fits_hddm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(final_b_cpp_df[\"animal_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_b_cpp_df.loc[(final_b_cpp_df[\"chosen_action\"]!=final_b_cpp_df[\"optimal\"])&(final_b_cpp_df[\"rewarded\"]==1)][[\"chosen_action\",\"optimal\",\"rewarded\",\"r_t0\",\"r_t1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_b_cpp_df.loc[final_b_cpp_df[\"condition\"]==\"iSPN-Stim\"].iloc[:100][[\"optimal\",\"chosen_action\",\"r_t0\",\"r_t1\",\"rewarded\",\"ideal_B\",\"condition\",\"conflict\",\"volatility\",\"cp\",\"b_t0\",\"b_t1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = final_b_cpp_df.loc[final_b_cpp_df[\"condition\"]==\"iSPN-Stim\"].iloc[:40].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test[\"volatility\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"session + block_num + trial_num\"] = [str(x)+\"-\"+str(z)+\"-\"+str(y)  for x,y,z in zip(test[\"session\"],test[\"trial_num\"],test[\"block_num\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"r_t0\",\"r_t1\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"r_t0\",\"r_t1\",\"b_t0\",\"b_t1\",\"chosen_action\",\"optimal\",\"ideal_B\",\"cpp\",\"learning_rate\",\"rewarded\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = pl.subplots(1,1,figsize=(15,6))\n",
    "sns.lineplot(x=\"session + block_num + trial_num\",y=\"b_t0\",data=test,ax=ax,label='b_t0',marker='o')\n",
    "sns.lineplot(x=\"session + block_num + trial_num\",y=\"b_t1\",data=test,ax=ax,label='b_t1',marker='o')\n",
    "sns.lineplot(x=\"session + block_num + trial_num\",y=\"r_t1\",data=test,ax=ax,label='r_t1',marker='o')\n",
    "sns.lineplot(x=\"session + block_num + trial_num\",y=\"r_t0\",data=test,ax=ax,label='r_t0',marker='o')\n",
    "sns.lineplot(x=\"session + block_num + trial_num\",y=\"cp\",data=test,ax=ax,label='cp',marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"conflict\",y=\"H(hazard_rate)\",col=\"volatility\",data=final_b_cpp_df,kind='point',hue='condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grp in final_b_cpp_df.groupby([\"condition\",\"conflict\",\"volatility\",\"session\"]):\n",
    "    print(grp[0])\n",
    "    print(len(np.where(grp[1][\"cp\"]==1)[0]), len(grp[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='conflict',y=\"ideal_B\",col='volatility',hue='condition',data=final_b_cpp_df,kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.07*0.5)/(0.5*0.07+0.75*0.93)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.07*0.5)/(0.5*0.07+0.9*0.93)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
